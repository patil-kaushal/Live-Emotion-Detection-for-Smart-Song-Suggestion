# Live-Emotion-Detection-for-Smart-Song-Suggestion

# ğŸµ Live Emotion Detection for Smart Song Suggestion

This project is a smart song recommender system that uses **live face emotion detection** to suggest personalized songs via **YouTube**, based on the user's mood, preferred **language**, and **singer**.

---

## ğŸ§  How It Works

1. The user opens the web app.
2. They enter:
   - Preferred **language** (e.g., Hindi, English)
   - Favorite **singer** (e.g., Arijit Singh)
3. The system opens a **Streamlit interface** that:
   - Captures **live video from webcam**
   - Detects user's facial and hand landmarks using **MediaPipe**
   - Predicts the **emotion** using a trained **Keras model**
4. On clicking **"Recommend me songs"**, it:
   - Creates a **YouTube search query** like:  
     `language + emotion + song + singer`
   - Opens YouTube in the browser with relevant results.

---

## ğŸš€ Tech Stack

- **Python**
- **MediaPipe** â€“ For real-time face & hand tracking
- **Keras / TensorFlow** â€“ For training & loading the emotion detection model
- **OpenCV** â€“ For video processing
- **Flask** â€“ Web routing
- **Streamlit** â€“ Real-time face emotion detection interface
- **YouTube** â€“ Used for song suggestions via query

---

## ğŸ“ Project Structure

liveEmoji-main/
â”œâ”€â”€ app.py # Flask backend
â”œâ”€â”€ music.py # Streamlit emotion detection logic
â”œâ”€â”€ data_collection.py # Data collection via webcam
â”œâ”€â”€ data_training.py # Model training script
â”œâ”€â”€ inference.py # Run standalone emotion detection
â”œâ”€â”€ model.h5 # Trained Keras model
â”œâ”€â”€ labels.npy # Label names for predictions
â”œâ”€â”€ templates/
â”‚ â””â”€â”€ index.html # Web UI
â”œâ”€â”€ static/
â”‚ â”œâ”€â”€ style.css # Styling
â”‚ â””â”€â”€ script.js # JS for animation
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md